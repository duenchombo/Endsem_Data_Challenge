{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 118082,
          "databundleVersionId": 14294892,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31153,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4e363fa918134819894d05ecfc3f624b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c9ca2e926074c70af0d4c296ffb9d3e"
            ],
            "layout": "IPY_MODEL_b21b5f419fd04f5fb03d7daba9f36247"
          }
        },
        "98b5ad4ab2dd4c83ae5519f9d11114ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2119781acb0455693fac9d1946b314a",
            "placeholder": "​",
            "style": "IPY_MODEL_0502b30502b347f4946334d14f4ea7d2",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "335f820caf2b4931931eba13eb19be70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_076f914afd214949b0a4673f64676dc0",
            "placeholder": "​",
            "style": "IPY_MODEL_e1cfde4269f44f00b845f3c9450d5229",
            "value": "duenchombo"
          }
        },
        "e563941bede04d5e85026d6473dcde8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6fa75db44115432c8aa9bde70219f311",
            "placeholder": "​",
            "style": "IPY_MODEL_ab5643e8df82406ea1b3b5a1210b0677",
            "value": ""
          }
        },
        "249f2b5fd44040c0b5b189f6b01df5ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_bae68a537dc249f4970b0fa67a69b185",
            "style": "IPY_MODEL_1ceebeaee03e4bb5bf0ace9e23d3e896",
            "tooltip": ""
          }
        },
        "5e5bdd8c79274c1b9cb0833309bcf3cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca47c62b25b948198fddabeacc962dfd",
            "placeholder": "​",
            "style": "IPY_MODEL_7eb953c2f6e44446b84ce370a0cd9f8c",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "b21b5f419fd04f5fb03d7daba9f36247": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "d2119781acb0455693fac9d1946b314a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0502b30502b347f4946334d14f4ea7d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "076f914afd214949b0a4673f64676dc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1cfde4269f44f00b845f3c9450d5229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fa75db44115432c8aa9bde70219f311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab5643e8df82406ea1b3b5a1210b0677": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bae68a537dc249f4970b0fa67a69b185": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ceebeaee03e4bb5bf0ace9e23d3e896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ca47c62b25b948198fddabeacc962dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eb953c2f6e44446b84ce370a0cd9f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9faf397e28e449919dfc5df8d5349c09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8262384b953d4a7b96dad5939e7b2c48",
            "placeholder": "​",
            "style": "IPY_MODEL_09b5cce109114b128a64c46bea3b6827",
            "value": "Connecting..."
          }
        },
        "8262384b953d4a7b96dad5939e7b2c48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09b5cce109114b128a64c46bea3b6827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c9ca2e926074c70af0d4c296ffb9d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcd67083a7654fe1bd824f78cc7f1948",
            "placeholder": "​",
            "style": "IPY_MODEL_04d2b5531e6d4e32b243ff9ca9e1a3d0",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "dcd67083a7654fe1bd824f78cc7f1948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04d2b5531e6d4e32b243ff9ca9e1a3d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: SOME KAGGLE DATA SOURCES ARE PRIVATE\n",
        "# RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES.\n",
        "import kagglehub\n",
        "kagglehub.login()\n",
        "# \"duenchombo\",\"8f66a46e93b156627591fadd91c3b1ba\"\n"
      ],
      "metadata": {
        "id": "BH_h2LUEV_4R",
        "outputId": "17e68e27-02ff-46af-b4bb-71cbe8ce14c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "4e363fa918134819894d05ecfc3f624b",
            "98b5ad4ab2dd4c83ae5519f9d11114ab",
            "335f820caf2b4931931eba13eb19be70",
            "e563941bede04d5e85026d6473dcde8a",
            "249f2b5fd44040c0b5b189f6b01df5ae",
            "5e5bdd8c79274c1b9cb0833309bcf3cb",
            "b21b5f419fd04f5fb03d7daba9f36247",
            "d2119781acb0455693fac9d1946b314a",
            "0502b30502b347f4946334d14f4ea7d2",
            "076f914afd214949b0a4673f64676dc0",
            "e1cfde4269f44f00b845f3c9450d5229",
            "6fa75db44115432c8aa9bde70219f311",
            "ab5643e8df82406ea1b3b5a1210b0677",
            "bae68a537dc249f4970b0fa67a69b185",
            "1ceebeaee03e4bb5bf0ace9e23d3e896",
            "ca47c62b25b948198fddabeacc962dfd",
            "7eb953c2f6e44446b84ce370a0cd9f8c",
            "9faf397e28e449919dfc5df8d5349c09",
            "8262384b953d4a7b96dad5939e7b2c48",
            "09b5cce109114b128a64c46bea3b6827",
            "9c9ca2e926074c70af0d4c296ffb9d3e",
            "dcd67083a7654fe1bd824f78cc7f1948",
            "04d2b5531e6d4e32b243ff9ca9e1a3d0"
          ]
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4e363fa918134819894d05ecfc3f624b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "da5401_2025_data_challenge_path = kagglehub.competition_download('da5401-2025-data-challenge')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "PvHIEDylV_4X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b43a2aed-3c0f-4da8-f6e4-23e3dfaf88ad"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": [
        "da5401_2025_data_challenge_path\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "B8qBQE1yYXX6",
        "outputId": "1dfe107e-8caf-42ec-bad2-0c316b081daa"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/competitions/da5401-2025-data-challenge'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU sentence-transformers\n",
        "!pip install -qU transformers huggingface_hub\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "AUQSpC40V_4Y"
      },
      "outputs": [],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import os"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T12:33:48.386167Z",
          "iopub.execute_input": "2025-11-11T12:33:48.38881Z",
          "iopub.status.idle": "2025-11-11T12:34:32.701827Z",
          "shell.execute_reply.started": "2025-11-11T12:33:48.388752Z",
          "shell.execute_reply": "2025-11-11T12:34:32.700588Z"
        },
        "id": "SWfds8eFV_4Y"
      },
      "outputs": [],
      "execution_count": 13
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_emb_dir='/root/.cache/kagglehub/competitions/da5401-2025-data-challenge/metric_name_embeddings.npy'\n",
        "metric_dir='/root/.cache/kagglehub/competitions/da5401-2025-data-challenge/metric_names.json'\n",
        "train_data_dir='/root/.cache/kagglehub/competitions/da5401-2025-data-challenge/train_data.json'\n",
        "test_data_dir='/root/.cache/kagglehub/competitions/da5401-2025-data-challenge/test_data.json'\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-11T12:34:48.308901Z",
          "iopub.execute_input": "2025-11-11T12:34:48.309998Z",
          "iopub.status.idle": "2025-11-11T12:34:48.317756Z",
          "shell.execute_reply.started": "2025-11-11T12:34:48.309934Z",
          "shell.execute_reply": "2025-11-11T12:34:48.316079Z"
        },
        "id": "BMOVnQcRV_4Z"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MODEL_NAME = \"microsoft/deberta-v3-small\"\n",
        "EPOCHS = 30\n",
        "BATCH_SIZE = 12\n",
        "LR = 1e-5\n",
        "MAX_LENGTH = 160"
      ],
      "metadata": {
        "id": "cTE-ZW_G4eY_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_training_data(train_json_path, metric_json_path, metric_npy_path):\n",
        "    # load metrics\n",
        "    with open(metric_json_path, \"r\") as f:\n",
        "        metric_names = json.load(f)\n",
        "\n",
        "    metric_embeddings = np.load(metric_npy_path)\n",
        "    metric_embeddings = metric_embeddings / np.linalg.norm(metric_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "    metric_to_embedding = {n: e for n, e in zip(metric_names, metric_embeddings)}\n",
        "\n",
        "    # load training df\n",
        "    df = pd.read_json(train_json_path)\n",
        "\n",
        "    # ---> FIX: ensure score is numeric\n",
        "    df[\"score\"] = pd.to_numeric(df[\"score\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"score\"])\n",
        "\n",
        "    # combined text\n",
        "    df[\"combined_text\"] = (\n",
        "        df[\"response\"].fillna(\"\") + \" \" +\n",
        "        df[\"user_prompt\"].fillna(\"\") + \" \" +\n",
        "        df[\"system_prompt\"].fillna(\"\")\n",
        "    )\n",
        "\n",
        "    return df, metric_to_embedding\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# SAMPLE WEIGHTS — MORE AGGRESSIVE (1 / freq^1.5)\n",
        "# ===============================================================\n",
        "def get_sample_weights(scores):\n",
        "    scores = np.array(scores)\n",
        "    unique, counts = np.unique(scores, return_counts=True)\n",
        "    freq = dict(zip(unique, counts))\n",
        "    weights = np.array([(1 / (freq[s] ** 1.5)) for s in scores], dtype=float)\n",
        "    return weights / weights.mean()\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# DATASET\n",
        "# ===============================================================\n",
        "class TextRegressionDataset(Dataset):\n",
        "    def __init__(self, df, tokenizer, metric_to_embedding):\n",
        "        self.texts = df[\"combined_text\"].tolist()\n",
        "        self.scores = df[\"score_norm\"].astype(float).tolist()\n",
        "        self.metric_names = df[\"metric_name\"].tolist()\n",
        "        self.metric_to_embedding = metric_to_embedding\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LENGTH,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        metric_emb = self.metric_to_embedding[self.metric_names[idx]]\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"metric_emb\": torch.tensor(metric_emb, dtype=torch.float),\n",
        "            \"score\": torch.tensor(self.scores[idx], dtype=torch.float)\n",
        "        }\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# MODEL — HEAVY REGULARIZATION\n",
        "# ===============================================================\n",
        "class MSRegressor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.enc = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        h = self.enc.config.hidden_size\n",
        "\n",
        "        # heavy regularization\n",
        "        self.dropout_layers = nn.ModuleList([nn.Dropout(0.45) for _ in range(5)])\n",
        "        self.fc = nn.Linear(h + 768, 1)\n",
        "\n",
        "    def forward(self, ids, mask, metric_emb, mc_dropout=False):\n",
        "        out = self.enc(ids, mask).last_hidden_state[:, 0, :]\n",
        "        x = torch.cat([out, metric_emb], dim=1)\n",
        "\n",
        "        if mc_dropout:\n",
        "            preds = [self.fc(d(x)) for d in self.dropout_layers]\n",
        "            return torch.mean(torch.stack(preds), dim=0).squeeze(1)\n",
        "\n",
        "        return self.fc(x).squeeze(1)\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# TRAIN LOOP\n",
        "# ===============================================================\n",
        "def train(train_json_path, metric_json_path, metric_npy_path):\n",
        "\n",
        "    # load data\n",
        "    df, metric_to_embedding = load_training_data(\n",
        "        train_json_path, metric_json_path, metric_npy_path\n",
        "    )\n",
        "\n",
        "    # normalize\n",
        "    score_mean = df[\"score\"].mean()\n",
        "    score_std = df[\"score\"].std()\n",
        "\n",
        "    df[\"score_norm\"] = (df[\"score\"] - score_mean) / score_std\n",
        "\n",
        "    # save normalization for inference\n",
        "    np.save(\"score_mean.npy\", np.array([score_mean]))\n",
        "    np.save(\"score_std.npy\", np.array([score_std]))\n",
        "\n",
        "    # split\n",
        "    df_train, df_temp = train_test_split(df, test_size=0.3, random_state=42)\n",
        "    df_val, df_test = train_test_split(df_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "    tok = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "    train_ds = TextRegressionDataset(df_train, tok, metric_to_embedding)\n",
        "    val_ds = TextRegressionDataset(df_val, tok, metric_to_embedding)\n",
        "    test_ds = TextRegressionDataset(df_test, tok, metric_to_embedding)\n",
        "\n",
        "    sampler = WeightedRandomSampler(\n",
        "        weights=get_sample_weights(df_train[\"score\"].values),\n",
        "        num_samples=len(df_train),\n",
        "        replacement=True\n",
        "    )\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler)\n",
        "    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "    model = MSRegressor().to(DEVICE)\n",
        "    opt = optim.AdamW(model.parameters(), lr=LR, weight_decay=0.06)\n",
        "\n",
        "    criterion = nn.HuberLoss(delta=1.0)\n",
        "\n",
        "    best_rmse = 999\n",
        "\n",
        "    # ============================\n",
        "    # TRAINING LOOP\n",
        "    # ============================\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\"):\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            metric_emb = batch[\"metric_emb\"].to(DEVICE)\n",
        "            y = batch[\"score\"].to(DEVICE)\n",
        "\n",
        "            opt.zero_grad()\n",
        "            preds = model(ids, mask, metric_emb)\n",
        "            loss = criterion(preds, y)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # ============================\n",
        "        # VALIDATION\n",
        "        # ============================\n",
        "        model.eval()\n",
        "        se = 0\n",
        "        n = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in val_loader:\n",
        "                ids = batch[\"input_ids\"].to(DEVICE)\n",
        "                mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "                metric_emb = batch[\"metric_emb\"].to(DEVICE)\n",
        "                y = batch[\"score\"].to(DEVICE)\n",
        "\n",
        "                preds = model(ids, mask, metric_emb, mc_dropout=True)\n",
        "                se += ((preds - y) ** 2).sum().item()\n",
        "                n += len(y)\n",
        "\n",
        "        rmse = np.sqrt(se / n)\n",
        "        print(f\"Epoch {epoch+1} | Val RMSE = {rmse:.4f}\")\n",
        "\n",
        "        if rmse < best_rmse:\n",
        "            best_rmse = rmse\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "            print(\"Saved new best model!\")\n",
        "\n",
        "    print(\"\\nTraining complete.\")\n",
        "    print(\"Best Validation RMSE:\", best_rmse)\n",
        "\n",
        "    return {\n",
        "        \"best_val_rmse\": best_rmse,\n",
        "        \"mean\": score_mean,\n",
        "        \"std\": score_std\n",
        "    }\n",
        "\n",
        "\n",
        "# ===============================================================\n",
        "# RUN\n",
        "# ===============================================================\n",
        "if __name__ == \"__main__\":\n",
        "    results = train(\n",
        "        train_json_path=train_data_dir,\n",
        "        metric_json_path=metric_dir,\n",
        "        metric_npy_path=numpy_emb_dir\n",
        "    )\n",
        "    print(\"RESULTS:\", results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N0_I35y72O8",
        "outputId": "7047489e-2a50-4ea1-b6ef-dd7cc07d6913"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n",
            "Epoch 1/30: 100%|██████████| 292/292 [01:17<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Val RMSE = 5.6104\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/30: 100%|██████████| 292/292 [01:17<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Val RMSE = 5.0603\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/30: 100%|██████████| 292/292 [01:17<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Val RMSE = 4.3480\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/30: 100%|██████████| 292/292 [01:17<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Val RMSE = 3.9902\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/30: 100%|██████████| 292/292 [01:17<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Val RMSE = 3.6999\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/30: 100%|██████████| 292/292 [01:17<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 | Val RMSE = 2.8651\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/30: 100%|██████████| 292/292 [01:17<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 | Val RMSE = 3.6801\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/30: 100%|██████████| 292/292 [01:17<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 | Val RMSE = 3.4851\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 | Val RMSE = 3.6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Val RMSE = 3.4766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 11/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 | Val RMSE = 3.4232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 12/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 | Val RMSE = 2.5513\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 13/30: 100%|██████████| 292/292 [01:17<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 | Val RMSE = 1.9714\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 14/30: 100%|██████████| 292/292 [01:17<00:00,  3.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 | Val RMSE = 1.5782\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 15/30: 100%|██████████| 292/292 [01:17<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 | Val RMSE = 2.0680\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 16/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 | Val RMSE = 2.0307\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 17/30: 100%|██████████| 292/292 [01:17<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 | Val RMSE = 2.1629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 18/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 | Val RMSE = 1.6423\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 19/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 | Val RMSE = 1.8098\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 20/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 | Val RMSE = 2.2840\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 21/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 | Val RMSE = 2.2552\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 22/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 | Val RMSE = 1.9946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 23/30: 100%|██████████| 292/292 [01:17<00:00,  3.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 | Val RMSE = 2.0518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 24/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 | Val RMSE = 1.8892\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 25/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 | Val RMSE = 1.6219\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 26/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 | Val RMSE = 1.6629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 27/30: 100%|██████████| 292/292 [01:17<00:00,  3.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 | Val RMSE = 1.8686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 28/30: 100%|██████████| 292/292 [01:17<00:00,  3.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 | Val RMSE = 1.2834\n",
            "Saved new best model!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 29/30: 100%|██████████| 292/292 [01:17<00:00,  3.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 | Val RMSE = 1.5555\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 30/30: 100%|██████████| 292/292 [01:18<00:00,  3.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 | Val RMSE = 1.7476\n",
            "\n",
            "Training complete.\n",
            "Best Validation RMSE: 1.2833802961863976\n",
            "RESULTS: {'best_val_rmse': np.float64(1.2833802961863976), 'mean': np.float64(9.1195), 'std': 0.9424157147861463}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "MODEL_NAME = \"microsoft/deberta-v3-small\"\n",
        "\n",
        "# ---------------------------\n",
        "# Paths (adjust if needed)\n",
        "# ---------------------------\n",
        "METRIC_JSON = \"/root/.cache/kagglehub/competitions/da5401-2025-data-challenge/metric_names.json\"\n",
        "METRIC_NPY  = \"/root/.cache/kagglehub/competitions/da5401-2025-data-challenge/metric_name_embeddings.npy\"\n",
        "TEST_JSON   = \"/root/.cache/kagglehub/competitions/da5401-2025-data-challenge/test_data.json\"\n",
        "MODEL_PATH  = \"best_model.pt\"\n",
        "MAX_LENGTH  = 160\n",
        "BATCH_SIZE  = 16\n",
        "MC_DROPOUT  = True"
      ],
      "metadata": {
        "id": "eJkNhlyk44sh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# Load metric embeddings (same code as training)\n",
        "# ----------------------------------------------------\n",
        "def load_metric_embeddings(json_path, npy_path):\n",
        "    with open(json_path, \"r\") as f:\n",
        "        metric_names = json.load(f)\n",
        "\n",
        "    metric_embs = np.load(npy_path)\n",
        "    metric_embs = metric_embs / np.linalg.norm(metric_embs, axis=1, keepdims=True)\n",
        "\n",
        "    return {n: e for n, e in zip(metric_names, metric_embs)}\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# SAME Dataset used in training (without scores)\n",
        "# ----------------------------------------------------\n",
        "class TextRegressionDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, df, tokenizer, metric_to_embedding):\n",
        "        self.texts = df[\"combined_text\"].tolist()\n",
        "        self.metric_names = df[\"metric_name\"].tolist()\n",
        "        self.metric_to_embedding = metric_to_embedding\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.texts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=MAX_LENGTH,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"input_ids\": enc[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0),\n",
        "            \"metric_emb\": torch.tensor(\n",
        "                self.metric_to_embedding[self.metric_names[idx]], dtype=torch.float\n",
        "            )\n",
        "        }\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# SAME Model class as training\n",
        "# ----------------------------------------------------\n",
        "class MSRegressor(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        from transformers import AutoModel\n",
        "        self.enc = AutoModel.from_pretrained(MODEL_NAME)\n",
        "        h = self.enc.config.hidden_size\n",
        "\n",
        "        self.dropout_layers = torch.nn.ModuleList([torch.nn.Dropout(0.45) for _ in range(5)])\n",
        "        self.fc = torch.nn.Linear(h + 768, 1)\n",
        "\n",
        "    def forward(self, ids, mask, metric_emb, mc_dropout=False):\n",
        "        out = self.enc(ids, mask).last_hidden_state[:, 0, :]\n",
        "        x = torch.cat([out, metric_emb], dim=1)\n",
        "\n",
        "        if mc_dropout:\n",
        "            preds = [self.fc(d(x)) for d in self.dropout_layers]\n",
        "            return torch.mean(torch.stack(preds), dim=0).squeeze(1)\n",
        "\n",
        "        return self.fc(x).squeeze(1)\n",
        "\n",
        "\n",
        "# ----------------------------------------------------\n",
        "# PREDICTION FUNCTION\n",
        "# ----------------------------------------------------\n",
        "def predict():\n",
        "\n",
        "    metric_map = load_metric_embeddings(METRIC_JSON, METRIC_NPY)\n",
        "\n",
        "    # Load test data\n",
        "    with open(TEST_JSON, \"r\") as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    df[\"combined_text\"] = (\n",
        "        df[\"response\"].fillna(\"\") + \" \" +\n",
        "        df[\"user_prompt\"].fillna(\"\") + \" \" +\n",
        "        df[\"system_prompt\"].fillna(\"\")\n",
        "    )\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    test_ds = TextRegressionDataset(df, tokenizer, metric_map)\n",
        "    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # -------------------------------\n",
        "    # Load trained model\n",
        "    # -------------------------------\n",
        "    model = MSRegressor().to(DEVICE)\n",
        "    model.load_state_dict(torch.load(\"best_model.pt\", map_location=DEVICE))\n",
        "    model.eval()\n",
        "\n",
        "    # Load normalization stats\n",
        "    score_mean = np.load(\"score_mean.npy\")[0]\n",
        "    score_std = np.load(\"score_std.npy\")[0]\n",
        "\n",
        "    preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            ids = batch[\"input_ids\"].to(DEVICE)\n",
        "            mask = batch[\"attention_mask\"].to(DEVICE)\n",
        "            metric_emb = batch[\"metric_emb\"].to(DEVICE)\n",
        "\n",
        "            out_norm = model(ids, mask, metric_emb, mc_dropout=MC_DROPOUT)\n",
        "\n",
        "            # unnormalize\n",
        "            out = out_norm.cpu().numpy() * score_std + score_mean\n",
        "            out = np.clip(out, 0, 10)\n",
        "\n",
        "            preds.extend(out.tolist())\n",
        "\n",
        "    # Build submission\n",
        "    sub = pd.DataFrame({\n",
        "        \"ID\": range(1, len(preds) + 1),\n",
        "        \"score\": preds\n",
        "    })\n",
        "    sub.to_csv(\"submission_fixed_30.csv\", index=False)\n",
        "    print(\"Saved submission_fixed_30.csv\")\n",
        "\n",
        "    # Rounded version\n",
        "    sub_r = sub.copy()\n",
        "    sub_r[\"score\"] = np.round(sub_r[\"score\"]).astype(int).clip(0, 10)\n",
        "    sub_r.to_csv(\"submission_fixed_rounded.csv\", index=False)\n",
        "    print(\"Saved submission_fixed_rounded.csv\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    predict()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvQ57rnzA5so",
        "outputId": "8ad6623f-9568-4a28-cd69-16f9477be15b"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved submission_fixed_30.csv\n",
            "Saved submission_fixed_rounded.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zv41057C6NV5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}